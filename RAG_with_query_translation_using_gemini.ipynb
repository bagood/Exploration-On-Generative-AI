{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eeaaf-07fc-4908-9ea1-e0d5afc5dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user --upgrade langchain python-dotenv google-generativeai langchain-google-genai langchain-community youtube-transcript-api chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e437c32c-77dc-4868-b719-ce7803a6c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r chroma_db/chroma_db_pdf_file\n",
    "!mkdir chroma_db/chroma_db_pdf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8dfac6-c70f-4b86-bd38-5e42fc848851",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY='INSERT THE GOOGLE API KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d456157b-ba4f-4317-8d9b-7477774f8600",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Set Environemnts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead449b9-e1f5-4556-8158-e4820a114ed4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34105dd7-fece-40ea-adf4-d097e96a5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.load import dumps, loads\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91318ccf-f513-4a6b-8d8c-17cd5ce87d46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  Load & Process Dataset, Then Create Retriever Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fee9eb-ea84-4415-b3b0-3e37882ee50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever_from_pdf_file(pdf_filename, k):\n",
    "    loader = PyPDFLoader(pdf_filename)\n",
    "    pages = loader.load_and_split()\n",
    "    \n",
    "    # splits the texts into several smaller documents, each containing chunks of the texts\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    for d in docs:\n",
    "        d.page_content = d.page_content.replace('\\n', ' ')\n",
    "    \n",
    "    # embed the documents and store it in a vector database\n",
    "    gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "                     documents=docs,                 # Data\n",
    "                     embedding=gemini_embeddings,    # Embedding model\n",
    "                     persist_directory=\"chroma_db/chroma_db_pdf_file\" # Directory to save data\n",
    "                     )\n",
    "    vectorstore_disk = Chroma(\n",
    "                        persist_directory=\"chroma_db/chroma_db_pdf_file\",       # Directory of db\n",
    "                        embedding_function=gemini_embeddings   # Embedding model\n",
    "                   )\n",
    "    \n",
    "    # a vector store retriever to retrieve the embedded documents\n",
    "    retriever = vectorstore_disk.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e290f6f-2195-4084-8948-fc0abe771061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726454722.283900       1 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "/tmp/ipykernel_1/3646112820.py:19: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 0.4. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vectorstore_disk = Chroma(\n"
     ]
    }
   ],
   "source": [
    "pdf_filename = \"History of LLM.pdf\"\n",
    "retriever = create_retriever_from_pdf_file(pdf_filename, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3393ffb-261b-4a26-af5c-9a9d0b1ff6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_query = 'What is a large language model?'\n",
    "complex_query = 'Explain to me the history of the large language model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c01e9aa7-c0f0-4576-b105-f241c8d0d63d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models are artificial neural networks (algorithms) that have gone from a recent development to widespread use within a few years. They have been instrumental in the development of ChatGPT, the next evolutionary step in artificial intelligence. Generative AI was combined with large language models to produce a smarter version of artificial intelligence. Large language models (LLMs) are based on artificial neural networks, and recent improvements in deep learning have supported \n",
      "\n",
      "improvements in deep learning have supported their development. A large language model also uses semantic technology (semantics, the semantic web, and natural language processes). The history of large language models starts with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. Bréal studied the ways languages are organized, how they change as time passes, and how words connect within a language. Currently, semantics is used for languages developed for \n",
      "\n",
      "even more advanced language models. A  large language model is a very large deep learning model that is pre-trained on massive  amounts of data. Deep learning is a form of machine learning, which is also a neural network,  but with additional layers. In 2011, deep learning began becoming popular. By 2018, deep learning algorithms were being used in every industry, from photography to online detail. Some of the ways deep learning applications were used include Apple’s Siri, automated drug \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(d.page_content, '\\n') for d in retriever.invoke(simple_query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c3fabc-5b93-4448-99a9-54c217a9a64e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improvements in deep learning have supported their development. A large language model also uses semantic technology (semantics, the semantic web, and natural language processes). The history of large language models starts with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. Bréal studied the ways languages are organized, how they change as time passes, and how words connect within a language. Currently, semantics is used for languages developed for \n",
      "\n",
      "Large language models are artificial neural networks (algorithms) that have gone from a recent development to widespread use within a few years. They have been instrumental in the development of ChatGPT, the next evolutionary step in artificial intelligence. Generative AI was combined with large language models to produce a smarter version of artificial intelligence. Large language models (LLMs) are based on artificial neural networks, and recent improvements in deep learning have supported \n",
      "\n",
      "The creation of the World Wide Web made the internet searchable and provided large language  models with access to massive amounts of information. The World Wide Web offers a platform  to create, store, locate, and share information on a variety of topics. During the mid-1990s, the  WWW initiated new levels of use on the internet, promoting interest in online shopping and what  was called “surfing” the internet. GPUs and Large Language Models Large language models require complex training, which \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(d.page_content, '\\n') for d in retriever.invoke(complex_query)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f51eb9-2df5-4860-81a6-ff100900c879",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RAG Using Gemini + Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d05b84-8a0f-4bd6-8e63-e2b339c6a7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def get_response_from_query(retriever, query):\n",
    "    # retrieve documents that has high similiarity with the given query\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    # create an instance of the gemini model\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "    # prompt text for the model \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"docs\"],\n",
    "        template=\"\"\"\n",
    "        You are a helpful assistant that can answer questions about large language model.\n",
    "        \n",
    "        Answer the following question: {query}\n",
    "        By searching the following informations: {docs}\n",
    "        \n",
    "        Only use the factual information from the given information to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        Your answers should be verbose and detailed.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # chain of steps to make rag prompt\n",
    "    rag_chain = (\n",
    "        {\"docs\": retriever | format_docs, # documents used inside the prompt are acquired from the retriever and formatted with the funcrion \"format_docs\"\n",
    "         \"query\": RunnablePassthrough()} # the query is provided in the input through applying the method of \"invoke\"\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    ) \n",
    "    \n",
    "    # make prompt based on the chain created\n",
    "    resp = rag_chain.invoke(query)\n",
    "\n",
    "    return resp, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d43066-65ef-4085-8519-a676e22c2e23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1/2980585872.py:6: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is a very large deep learning model that is pre-trained on massive amounts of data. Deep learning is a form of machine learning, which is also a neural network, but with additional layers. LLMs are based on artificial neural networks, and recent improvements in deep learning have supported their development. LLMs also use semantic technology (semantics, the semantic web, and natural language processes).\n"
     ]
    }
   ],
   "source": [
    "resp, docs = get_response_from_query(retriever, simple_query)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27c04e8f-256b-4e8f-9f30-1c95cf7572b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The history of large language models:**\n",
      "\n",
      "In 1883, French philologist Michel Bréal developed the concept of semantics, which is the study of the ways languages are organized, how they change over time, and how words connect within a language. Today, semantics is used in the development of languages for large language models.\n",
      "\n",
      "Large language models are based on artificial neural networks, and recent improvements in deep learning have supported their development. \n",
      "\n",
      "The creation of the World Wide Web made the internet searchable and provided large language models with access to massive amounts of information.\n"
     ]
    }
   ],
   "source": [
    "resp, docs = get_response_from_query(retriever, complex_query)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79a7bc-7035-46a7-a965-e5c94e673468",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Retrieval Augmented Generation with Query Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d410d-abc0-493e-b7be-20e19344cd3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RAG with Multi-Query Using Gemini + Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a78b21d-7693-4c5e-a852-44426f78295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain_for_generating_more_queries():\n",
    "    # prompt text for generating more queries from a query\n",
    "    template = \"\"\"\n",
    "    You are an AI language model assistant. \n",
    "    Your task is to generate three shorter versions of the given user question with each version have unique perspectives.\n",
    "    These shorter versions of the given user question will be used to retrieve relevant documents from a vector database. \n",
    "    By generating multiple shorter versions of the given user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these shorter version questions separated by newlines.\n",
    "    The given questions is: {query}\n",
    "    \"\"\"\n",
    "    prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # create an instance of the gemini model\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    # chain of steps to generate more queries \n",
    "    generate_queries = (\n",
    "        prompt_perspectives \n",
    "        | llm\n",
    "        | StrOutputParser() \n",
    "        | (lambda x: x.split(\"\\n\"))\n",
    "    )\n",
    "    \n",
    "    return generate_queries\n",
    "\n",
    "def _get_unique_union(documents):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    \n",
    "    return '\\n\\n'.join([loads(doc).page_content for doc in unique_docs])\n",
    "\n",
    "def create_retrieval_chain(generate_queries, retriever):\n",
    "    retrieval_chain = generate_queries | retriever.map() | _get_unique_union\n",
    "    \n",
    "    return retrieval_chain\n",
    "\n",
    "def get_response_from_multi_query(retrieval_chain, query):\n",
    "    # retrieve documents that has high similarity with the given query\n",
    "    docs = retrieval_chain.invoke({\"query\":query})\n",
    "    \n",
    "    # create an instance of the gemini model\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    # prompt text for the model \n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant to answer questions about large language model.\n",
    "    \n",
    "    Below is the question to answer.\n",
    "    {query}\n",
    "    \n",
    "    Utilize the following information to generate the answer.\n",
    "    {docs}\n",
    "    \n",
    "    Only use the factual information from the given information to answer the question.\n",
    "    If you feel like you don't have enough information to answer the question, say \"I don't know\"\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # chain of steps to make rag prompt\n",
    "    rag_chain = (\n",
    "        {\"docs\": retrieval_chain, \n",
    "         \"query\": itemgetter(\"query\")} \n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # make prompt based on the chain created\n",
    "    resp = rag_chain.invoke({\"query\":query})\n",
    "        \n",
    "    return resp, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b7f9665-5df7-4d97-b243-fa30d935f8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_queries = create_chain_for_generating_more_queries()\n",
    "retrieval_chain = create_retrieval_chain(generate_queries, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d6ebe1-dc4e-47a0-ba46-b0bbd824096b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- What are the key characteristics of a large language model?\n",
      "- How do large language models compare to traditional natural language processing models?\n",
      "- What are the potential applications of large language models?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1/734419216.py:33: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return '\\n\\n'.join([loads(doc).page_content for doc in unique_docs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models are artificial neural networks (algorithms) that have gone from a recent development to widespread use within a few years. \n",
      "\n",
      "The creation of the World Wide Web made the internet searchable and provided large language  models with access to massive amounts of information. The World Wide Web offers a platform  to create, store, locate, and share information on a variety of topics. During the mid-1990s, the  WWW initiated new levels of use on the internet, promoting interest in online shopping and what  was called “surfing” the internet. GPUs and Large Language Models Large language models require complex training, which\n",
      "\n",
      "Large language models are artificial neural networks (algorithms) that have gone from a recent development to widespread use within a few years. They have been instrumental in the development of ChatGPT, the next evolutionary step in artificial intelligence. Generative AI was combined with large language models to produce a smarter version of artificial intelligence. Large language models (LLMs) are based on artificial neural networks, and recent improvements in deep learning have supported\n",
      "\n",
      "improvements in deep learning have supported their development. A large language model also uses semantic technology (semantics, the semantic web, and natural language processes). The history of large language models starts with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. Bréal studied the ways languages are organized, how they change as time passes, and how words connect within a language. Currently, semantics is used for languages developed for\n"
     ]
    }
   ],
   "source": [
    "[print(v) for v in generate_queries.invoke(simple_query)]\n",
    "print()\n",
    "\n",
    "resp, docs = get_response_from_multi_query(retrieval_chain, simple_query)\n",
    "\n",
    "print(resp, '\\n')\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d46fa5f-dd9a-4ef9-9d37-07debc13aac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The development and evolution of large language models\n",
      "- A historical overview of the advancements in large language models\n",
      "- The timeline of key milestones in the history of large language models\n",
      "\n",
      "The history of large language models begins with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. Bréal studied the ways languages are organized, how they change as time passes, and how words connect within a language. Currently, semantics is used for languages developed for machine learning. \n",
      "\n",
      "to work with neural networks. ML was used to answer phones and perform a variety of automated tasks. Small Language Models Early development of the first (small) language models was started in the 1980s by IBM, and  they were/are designed to predict the next word in a sentence. Part of their design includes a  “dictionary,” which determines how often certain words occur within the text the model was  trained on. After each word, the algorithm recalculates statistically what the following word\n",
      "\n",
      "and human languages. How Natural Language Processing Was Almost Lost Before It Started From 1906 to 1912, Ferdinand de Saussure taught Indo-European linguistics, general linguistics, and Sanskrit at the University of Geneva. During this time he developed the foundation for a highly functional model of languages as systems. Then, in 1913, he died, before organizing and publishing his work. Fortunately, Albert Sechehaye and Charles Bally, two instructors who were also Saussure’s  colleagues,\n",
      "\n",
      "Large language models are artificial neural networks (algorithms) that have gone from a recent development to widespread use within a few years. They have been instrumental in the development of ChatGPT, the next evolutionary step in artificial intelligence. Generative AI was combined with large language models to produce a smarter version of artificial intelligence. Large language models (LLMs) are based on artificial neural networks, and recent improvements in deep learning have supported\n",
      "\n",
      "improvements in deep learning have supported their development. A large language model also uses semantic technology (semantics, the semantic web, and natural language processes). The history of large language models starts with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. Bréal studied the ways languages are organized, how they change as time passes, and how words connect within a language. Currently, semantics is used for languages developed for\n"
     ]
    }
   ],
   "source": [
    "[print(v) for v in generate_queries.invoke(complex_query)]\n",
    "print()\n",
    "\n",
    "resp, docs = get_response_from_multi_query(retrieval_chain, complex_query)\n",
    "\n",
    "print(resp, '\\n')\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d64f2-7a9c-4f5d-ae15-d11921d5ce78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RAG-Fusion Using Gemini + Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3787ea-c0f9-4626-9c6c-de7ac388f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain_for_generating_more_queries():\n",
    "    # prompt text for generating more queries from a query\n",
    "    template = \"\"\"\n",
    "    You are an AI language model assistant. \n",
    "    Your task is to generate three shorter versions of the given user question with each version have unique perspectives.\n",
    "    These shorter versions of the given user question will be used to retrieve relevant documents from a vector database. \n",
    "    By generating multiple shorter versions of the given user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these shorter version questions separated by newlines.\n",
    "    The given questions is: {query}\n",
    "    \"\"\"\n",
    "    prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # create an instance of the gemini model\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    # chain of steps to generate more queries \n",
    "    generate_queries = (\n",
    "        prompt_perspectives \n",
    "        | llm\n",
    "        | StrOutputParser() \n",
    "        | (lambda x: x.split(\"\\n\"))\n",
    "    )\n",
    "    \n",
    "    return generate_queries\n",
    "\n",
    "def _reciprocal_rank_fusion(results, k=5):    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ][:k]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return '\\n\\n'.join([doc.page_content for doc, score in reranked_results])\n",
    "\n",
    "def create_retrieval_chain(generate_queries, retriever):\n",
    "    retrieval_chain = generate_queries | retriever.map() | _reciprocal_rank_fusion\n",
    "    \n",
    "    return retrieval_chain\n",
    "\n",
    "def get_response_from_rag_fusion(retrieval_chain, query):\n",
    "    # retrieve documents that has high similarity with the given query\n",
    "    docs = retrieval_chain.invoke({\"query\":query})\n",
    "    \n",
    "    # create an instance of the gemini model\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    # prompt text for the model \n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant to answer questions about large language models.\n",
    "    \n",
    "    Below is the question to answer.\n",
    "    {query}\n",
    "    \n",
    "    Utilize the following information to generate the answer.\n",
    "    {docs}\n",
    "    \n",
    "    Only use the factual information from the given information to answer the question.\n",
    "    If you feel like you don't have enough information to answer the question, say \"I don't know\"\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    rag_chain = (   \n",
    "        {\"docs\": retrieval_chain, \n",
    "         \"query\": itemgetter(\"query\")} \n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()  \n",
    "    )\n",
    "\n",
    "    # make prompt based on the chain created\n",
    "    resp = rag_chain.invoke({\"query\":query})\n",
    "        \n",
    "    return resp, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "101f3cff-e92f-4c28-a604-c6c4f1db8bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_queries = create_chain_for_generating_more_queries()\n",
    "retrieval_chain = create_retrieval_chain(generate_queries, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c510770-4613-4040-862c-46b377527fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Characteristics of large language models\n",
      "- Applications of large language models\n",
      "- Comparison of large language models to other language models\n",
      "\n",
      "A large language model is an artificial neural network that uses semantic technology to understand and generate human language. \n",
      "\n",
      "Large language models are artificial neural networks (algorithms) that have gone from a recent development to widespread use within a few years. They have been instrumental in the development of ChatGPT, the next evolutionary step in artificial intelligence. Generative AI was combined with large language models to produce a smarter version of artificial intelligence. Large language models (LLMs) are based on artificial neural networks, and recent improvements in deep learning have supported\n",
      "\n",
      "improvements in deep learning have supported their development. A large language model also uses semantic technology (semantics, the semantic web, and natural language processes). The history of large language models starts with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. Bréal studied the ways languages are organized, how they change as time passes, and how words connect within a language. Currently, semantics is used for languages developed for\n",
      "\n",
      "The creation of the World Wide Web made the internet searchable and provided large language  models with access to massive amounts of information. The World Wide Web offers a platform  to create, store, locate, and share information on a variety of topics. During the mid-1990s, the  WWW initiated new levels of use on the internet, promoting interest in online shopping and what  was called “surfing” the internet. GPUs and Large Language Models Large language models require complex training, which\n",
      "\n",
      "to work with neural networks. ML was used to answer phones and perform a variety of automated tasks. Small Language Models Early development of the first (small) language models was started in the 1980s by IBM, and  they were/are designed to predict the next word in a sentence. Part of their design includes a  “dictionary,” which determines how often certain words occur within the text the model was  trained on. After each word, the algorithm recalculates statistically what the following word\n"
     ]
    }
   ],
   "source": [
    "[print(v) for v in generate_queries.invoke(simple_query)]\n",
    "print()\n",
    "\n",
    "resp, docs = get_response_from_multi_query(retrieval_chain, simple_query)\n",
    "\n",
    "print(resp, '\\n')\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c9a2a7-d2e8-4e92-9261-65ef2bd8e4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- History of large language models\n",
      "- Evolution of large language models over time\n",
      "- Timeline of significant events in the development of large language models\n",
      "\n",
      "The history of large language models starts with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. From 1906 to 1912, Ferdinand de Saussure taught Indo-European linguistics, general linguistics, and Sanskrit at the University of Geneva. During this time he developed the foundation for a highly functional model of languages as systems. Early development of the first (small) language models was started in the 1980s by IBM. \n",
      "\n",
      "improvements in deep learning have supported their development. A large language model also uses semantic technology (semantics, the semantic web, and natural language processes). The history of large language models starts with the concept of semantics, developed by the French philologist, Michel Bréal, in 1883. Bréal studied the ways languages are organized, how they change as time passes, and how words connect within a language. Currently, semantics is used for languages developed for\n",
      "\n",
      "Large language models are artificial neural networks (algorithms) that have gone from a recent development to widespread use within a few years. They have been instrumental in the development of ChatGPT, the next evolutionary step in artificial intelligence. Generative AI was combined with large language models to produce a smarter version of artificial intelligence. Large language models (LLMs) are based on artificial neural networks, and recent improvements in deep learning have supported\n",
      "\n",
      "and human languages. How Natural Language Processing Was Almost Lost Before It Started From 1906 to 1912, Ferdinand de Saussure taught Indo-European linguistics, general linguistics, and Sanskrit at the University of Geneva. During this time he developed the foundation for a highly functional model of languages as systems. Then, in 1913, he died, before organizing and publishing his work. Fortunately, Albert Sechehaye and Charles Bally, two instructors who were also Saussure’s  colleagues,\n",
      "\n",
      "to work with neural networks. ML was used to answer phones and perform a variety of automated tasks. Small Language Models Early development of the first (small) language models was started in the 1980s by IBM, and  they were/are designed to predict the next word in a sentence. Part of their design includes a  “dictionary,” which determines how often certain words occur within the text the model was  trained on. After each word, the algorithm recalculates statistically what the following word\n"
     ]
    }
   ],
   "source": [
    "[print(v) for v in generate_queries.invoke(complex_query)]\n",
    "print()\n",
    "\n",
    "resp, docs = get_response_from_multi_query(retrieval_chain, complex_query)\n",
    "\n",
    "print(resp, '\\n')\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817256e-d7ec-4789-b60d-41e1eeecb89d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RAG with Query Decomposition Using Gemini + Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4907bc56-4037-4308-9938-f0bb8957ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_query(query):\n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant that generates multiple differently phrased query related to the given query\n",
    "    The goal is to break down the query into several queries that can be answered in isolation\n",
    "    Generate multiple differently phrased query related to: {query}\n",
    "    Output (3 queries):\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_decomposition = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "    # LLM\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "    # Chain\n",
    "    generate_queries_decomposition = (prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "    \n",
    "    # Run\n",
    "    decomposed_query = generate_queries_decomposition.invoke({\"query\":query})\n",
    "    \n",
    "    return decomposed_query\n",
    "\n",
    "def format_question_answer(query, answer):\n",
    "    formatted_string = f\"\"\"Question:{query}\n",
    "                           Solution:{answer}\"\"\"\n",
    "    \n",
    "    return formatted_string\n",
    "\n",
    "def get_response_from_rag_with_decomposition(retriever, query, decomposed_query):\n",
    "    # create an instance of the gemini model\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    # prompt text for the model \n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant to answer questions about large language model.\n",
    "\n",
    "    Below is the question to answer.\n",
    "\n",
    "    \\n --- \\n {query} \\n --- \\n\n",
    "\n",
    "    Utilize these available background question + answer pairs below to answer the question.\n",
    "\n",
    "    \\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "    Utilize the following information to generate the answer.\n",
    "\n",
    "    \\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "    Use the above informations and any background question + answer pairs to answer the question\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    q_a_pairs = \"\"\n",
    "    for q in decomposed_query:\n",
    "        rag_chain = (\n",
    "        {\"context\": itemgetter(\"query\") | retriever, \n",
    "         \"query\": itemgetter(\"query\"),\n",
    "         \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser())\n",
    "\n",
    "        answer = rag_chain.invoke({\"query\":q,\"q_a_pairs\":q_a_pairs})\n",
    "        q_a_pair = format_question_answer(q, answer)\n",
    "        q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n",
    "                \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2e22cd6-240f-4621-8b1a-3d819044cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models (LLMs) are a type of artificial neural network that has been trained on a massive dataset of text and code. This training allows LLMs to understand the structure and meaning of human language, and to generate new text that is both coherent and informative.\n",
      "\n",
      "LLMs have a wide range of capabilities, including:\n",
      "\n",
      "* **Natural language processing:** LLMs can be used to perform a variety of natural language processing tasks, such as text classification, named entity recognition, and machine translation.\n",
      "* **Text generation:** LLMs can be used to generate new text, such as articles, stories, and code.\n",
      "* **Dialogue generation:** LLMs can be used to generate dialogue, such as customer service conversations and chatbot responses.\n",
      "* **Question answering:** LLMs can be used to answer questions about the world, based on the information they have been trained on.\n",
      "\n",
      "LLMs are still under development, but they have already shown great promise for a variety of applications. As LLMs continue to improve, they are likely to have an even greater impact on our lives.\n"
     ]
    }
   ],
   "source": [
    "decomposed_query = decompose_query(simple_query)\n",
    "\n",
    "resp = get_response_from_rag_with_decomposition(retriever, simple_query, decomposed_query)\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44f7636f-7a82-4023-b48d-90af182f0b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key milestones in the development of large language models (LLMs) include:\n",
      "\n",
      "* **1883:** French philologist Michel Bréal develops the concept of semantics, which studies the meaning of words and how they are used in language.\n",
      "* **1980s:** Small language models (SLMs) are developed to predict the next word in a sentence.\n",
      "* **Recent years:**\n",
      "    * LLMs are developed using artificial neural networks and deep learning.\n",
      "    * LLMs are used to develop generative AI, which can generate new text, images, and other content.\n",
      "    * The World Wide Web provides access to massive amounts of information, which LLMs use to train their models.\n"
     ]
    }
   ],
   "source": [
    "decomposed_query = decompose_query(complex_query)\n",
    "\n",
    "resp = get_response_from_rag_with_decomposition(retriever, complex_query, decomposed_query)\n",
    "\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
